<!DOCTYPE html>
<html>
  <head>
    <title>OpenAI CLIP JavaScript - Image Demo - ONNX Web Runtime</title>
  </head>
  <body>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.12.0/dist/ort.js"></script>
    
    <div>
        <img id="img" src="https://hotpotmedia.s3.us-east-2.amazonaws.com/8-qzBN4LDalyepSX6.png" width="256" height="256">
        


      <!-- karpathy: https://i.imgur.com/WEIKDpX.jpg -->
      <!-- 512px astronaut: https://i.imgur.com/ec4Ao4s.png -->
      <br>
      backend: <select id="backendSelectEl">
        <option>wasm</option>
      </select>
      <br>
      quantized: <select id="quantizedSelectEl">
        <option value="no">no</option>
        <option value="yes">yes (4x smaller model, but currently the predicitions might be inaccurate)</option>
      </select>
      <br>
    </div>
    <p><a href="https://github.com/josephrocca/openai-clip-js">github repo</a> - <a href="https://huggingface.co/rocca/openai-clip-js/tree/main">huggingface repo</a></p>
    
    <script>
      if(self.crossOriginIsolated) { // needs to be cross-origin-isolated to use wasm threads. you need to serve this html file with these two headers: https://web.dev/coop-coep/
        ort.env.wasm.numThreads = navigator.hardwareConcurrency
      }
      
      async function main() {
        startBtn.disabled = true;
        startBtn.innerHTML = "see console";

        console.log("Loading text model... (see network tab for progress)");
        let modelPatht = quantizedSelectEl.value === "no" ? 'https://huggingface.co/rocca/openai-clip-js/resolve/main/clip-text-vit-32-float32-int32.onnx' : 'https://huggingface.co/rocca/openai-clip-js/resolve/main/clip-text-vit-32-uint8.onnx';
        const sessions = await ort.InferenceSession.create(modelPatht, { executionProviders: ["wasm"] });
        //console.log("Model loaded.");
        
        let Tokenizer = (await import("https://deno.land/x/clip_bpe@v0.0.6/mod.js")).default;
        let t = new Tokenizer();
        
        let textTokens = t.encodeForCLIP("Drawing");
        textTokens1 = t.encodeForCLIP("Hentai");
        textTokens2 = t.encodeForCLIP("Neutral");
        textTokens3 = t.encodeForCLIP("Sexy");
        textTokens4 = t.encodeForCLIP("porn");

        textTokens = Int32Array.from(textTokens);
        textTokens1 = Int32Array.from(textTokens1);
        textTokens2 = Int32Array.from(textTokens2);
        textTokens3 = Int32Array.from(textTokens3);
        textTokens4 = Int32Array.from(textTokens4);

        const feedss = {'input': new ort.Tensor('int32', textTokens, [1, 77])};
        const feedss1 = {'input': new ort.Tensor('int32', textTokens1, [1, 77])};
        const feedss2 = {'input': new ort.Tensor('int32', textTokens2, [1, 77])};
        const feedss3 = {'input': new ort.Tensor('int32', textTokens3, [1, 77])};
        const feedss4 = {'input': new ort.Tensor('int32', textTokens4, [1, 77])};

        //console.log("Running inference...");
        const resultss = await sessions.run(feedss);
        const resultss1 = await sessions.run(feedss1);
        const resultss2 = await sessions.run(feedss2);
        const resultss3 = await sessions.run(feedss3);
        const resultss4 = await sessions.run(feedss4);
        //console.log("Finished inference.");
        const dataa = resultss["output"].data;
        const dataa1 = resultss1["output"].data;
        const dataa2 = resultss2["output"].data;
        const dataa3 = resultss3["output"].data;
        const dataa4 = resultss4["output"].data;

        console.log("Downloading image model... (see network tab for progress)");
        // let modelPath = backendSelectEl.value === "webgl" ? './clip-image-vit-32-int32-float32.onnx' : './clip-image-vit-32-float32.onnx';
        let modelPath = quantizedSelectEl.value === "no" ? 'https://huggingface.co/rocca/openai-clip-js/resolve/main/clip-image-vit-32-float32.onnx' : 'https://huggingface.co/rocca/openai-clip-js/resolve/main/clip-image-vit-32-uint8.onnx';
        const session = await ort.InferenceSession.create(modelPath, { executionProviders: [backendSelectEl.value] });
        console.log("Models loaded.");

        let rgbData = await getRgbData(img.src);

        const feeds = {'input': new ort.Tensor('float32', rgbData, [1,3,224,224])};

        console.log("Running inference...");
        const results = await session.run(feeds);
        console.log("Finished inference.");

        const data = results["output"].data;
        //console.log(`data of result tensor 'output'`, data);

        // cosine smilarity between text and image embeddings openai clip
        const dot = dataa.reduce((acc, val, i) => acc + val * data[i], 0);
        const norm1 = Math.sqrt(dataa.reduce((acc, val) => acc + val * val, 0));
        const norm2 = Math.sqrt(data.reduce((acc, val) => acc + val * val, 0));
        const cos = dot / (norm1 * norm2);

        const dot1 = dataa1.reduce((acc, val, i) => acc + val * data[i], 0);
        const norm11 = Math.sqrt(dataa1.reduce((acc, val) => acc + val * val, 0));
        const norm21 = Math.sqrt(data.reduce((acc, val) => acc + val * val, 0));
        const cos1 = dot1 / (norm11 * norm21);

        const dot2 = dataa2.reduce((acc, val, i) => acc + val * data[i], 0);
        const norm12 = Math.sqrt(dataa2.reduce((acc, val) => acc + val * val, 0));
        const norm22 = Math.sqrt(data.reduce((acc, val) => acc + val * val, 0));
        const cos2 = dot2 / (norm12 * norm22);

        const dot3 = dataa3.reduce((acc, val, i) => acc + val * data[i], 0);
        const norm13 = Math.sqrt(dataa3.reduce((acc, val) => acc + val * val, 0));
        const norm23 = Math.sqrt(data.reduce((acc, val) => acc + val * val, 0));
        const cos3 = dot3 / (norm13 * norm23);

        const dot4 = dataa4.reduce((acc, val, i) => acc + val * data[i], 0);
        const norm14 = Math.sqrt(dataa4.reduce((acc, val) => acc + val * val, 0));
        const norm24 = Math.sqrt(data.reduce((acc, val) => acc + val * val, 0));
        const cos4 = dot4 / (norm14 * norm24);

        // cosine similarity in percentage
        const cosPercentage = Math.round(cos * 100);
        const cosPercentage1 = Math.round(cos1 * 100);
        const cosPercentage2 = Math.round(cos2 * 100);
        const cosPercentage3 = Math.round(cos3 * 100);
        const cosPercentage4 = Math.round(cos4 * 100);
        
        // display results
        console.log(`Drawing: ${cosPercentage}%`);
        console.log(`Hentai: ${cosPercentage1}%`);
        console.log(`Neutral: ${cosPercentage2}%`);
        console.log(`Sexy: ${cosPercentage3}%`);
        console.log(`Porn: ${cosPercentage4}%`);  

      }
     
      async function getRgbData(imgUrl) {
        let blob = await fetch(imgUrl, {referrer:""}).then(r => r.blob());
        let img = await createImageBitmap(blob);

        let canvas = new OffscreenCanvas(224, 224);
        let ctx = canvas.getContext("2d");
        ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
        let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

        let rgbData = [[], [], []]; // [r, g, b]
        // remove alpha and put into correct shape:
        let d = imageData.data;
        for(let i = 0; i < d.length; i += 4) { 
          let x = (i/4) % canvas.width;
          let y = Math.floor((i/4) / canvas.width)
          if(!rgbData[0][y]) rgbData[0][y] = [];
          if(!rgbData[1][y]) rgbData[1][y] = [];
          if(!rgbData[2][y]) rgbData[2][y] = [];
          rgbData[0][y][x] = d[i+0]/255;
          rgbData[1][y][x] = d[i+1]/255;
          rgbData[2][y][x] = d[i+2]/255;
          // From CLIP repo: Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))
          rgbData[0][y][x] = (rgbData[0][y][x] - 0.48145466) / 0.26862954;
          rgbData[1][y][x] = (rgbData[1][y][x] - 0.4578275) / 0.26130258;
          rgbData[2][y][x] = (rgbData[2][y][x] - 0.40821073) / 0.27577711;
        }
        rgbData = Float32Array.from(rgbData.flat().flat());
        return rgbData;
      }
    </script>
  </body>
</html>